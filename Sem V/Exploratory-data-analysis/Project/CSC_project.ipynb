{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Score Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display every column\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv(filepath_or_buffer='./Data/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate entries in the dataset\n",
    "\n",
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values from every column\n",
    "\n",
    "columns = df.columns\n",
    "for column in columns:\n",
    "    print(f'{column}: {df[column].unique()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find errors in the SSN column\n",
    "\n",
    "SSN_regex_pattern = r'^\\d{3}-\\d{2}-\\d{4}$'\n",
    "\n",
    "invalid_ssns = ~df['SSN'].str.match(pat=SSN_regex_pattern, na=True)\n",
    "invalid_ssns.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview incorrect SSN entries\n",
    "\n",
    "df.loc[invalid_ssns, 'SSN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all the info for records with incorrect SSNs\n",
    "\n",
    "invalid_ssns_info = df.loc[invalid_ssns, :]\n",
    "invalid_ssns_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing errors in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove incorrect entries from the SSN column\n",
    "\n",
    "invalid_ssn_customer_IDs = invalid_ssns_info['Customer_ID'].unique()\n",
    "\n",
    "for customer in invalid_ssn_customer_IDs:\n",
    "    # Filter rows for the current Customer_ID\n",
    "    customer_rows = df[df['Customer_ID'] == customer]\n",
    "    # Extract valid SSN values if found\n",
    "    valid_ssns = customer_rows['SSN'].dropna().unique()\n",
    "    # Update the SSN for the customer with a valid one, if found\n",
    "    if len(valid_ssns) > 0:\n",
    "        df.loc[df['Customer_ID'] == customer, 'SSN'] = valid_ssns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['SSN'] == '#F%$D@*&8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Customer_ID'] == 'CUS_0x132f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing underscores from the data\n",
    "\n",
    "df['Age'] = df['Age'].str.strip(to_strip='_')\n",
    "df['Annual_Income'] = df['Annual_Income'].str.strip(to_strip='_')\n",
    "df['Num_of_Loan'] = df['Num_of_Loan'].str.strip(to_strip='_')\n",
    "df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].str.strip(to_strip='_')\n",
    "df['Outstanding_Debt'] = df['Outstanding_Debt'].str.strip(to_strip='_')\n",
    "\n",
    "for column in columns:\n",
    "    print(f'{column}: {df[column].unique()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the underscore entries from the Occupation column\n",
    "\n",
    "df.loc[df['Occupation'] == '_______']\n",
    "\n",
    "df = df.loc[df['Occupation'] != '_______']\n",
    "\n",
    "# Remove the underscore entries from the Changed_Credit_Limit column\n",
    "\n",
    "df.loc[df['Changed_Credit_Limit'] == '_']\n",
    "\n",
    "df = df.loc[df['Changed_Credit_Limit'] != '_']\n",
    "\n",
    "# Remove the underscore entries from the Credit_Mix column\n",
    "\n",
    "df.loc[df['Credit_Mix'] == '_']\n",
    "\n",
    "df = df.loc[df['Credit_Mix'] != '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid entries (negative values, overestimated values)\n",
    "\n",
    "# Fill in incorrect ages\n",
    "\n",
    "incorrect_ages = df.loc[\n",
    "    ~(df['Age'].astype(str).str.match(r'^\\d{2,3}$'))\n",
    "    | (df['Age'].astype(str).str.contains('-'))\n",
    "    | (df['Age'].astype(int) > 120)\n",
    "]\n",
    "\n",
    "df_dropped_ages = df[~df.index.isin(incorrect_ages.index)]\n",
    "incorrect_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the age on other records with the same Customer_ID\n",
    "\n",
    "df.loc[df['Customer_ID'] == 'CUS_0x6a1b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of valid age records and update the incorrect Age column records\n",
    "\n",
    "for customer_id in incorrect_ages['Customer_ID'].unique():\n",
    "    # Get all age inputs for the customer with a specific Customer_ID, excluding incorrect ages\n",
    "    correct_ages = df.loc[(df['Customer_ID'] == customer_id) & ~(df.index.isin(incorrect_ages.index)), 'Age']\n",
    "\n",
    "    # Convert correct ages to numeric values\n",
    "    correct_ages_numeric = pd.to_numeric(correct_ages, errors='coerce')\n",
    "\n",
    "    # Calculate and round the mean of correct ages\n",
    "    mean_age = np.nanmean(correct_ages_numeric)\n",
    "    mean_age = mean_age.round().astype(int)\n",
    "\n",
    "    # Update incorrect ages in the original dataframe\n",
    "    mask = (df['Customer_ID'] == customer_id) & (df.index.isin(incorrect_ages.index))\n",
    "    df.loc[mask, 'Age'] = mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Customer_ID'] == 'CUS_0x4080']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove incorrect entries from the Payment_Behaviour column\n",
    "\n",
    "df.loc[df['Payment_Behaviour'] == '!@9#%8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Customer_ID'] == 'CUS_0x95ee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replace_payment_behavior = df['Payment_Behaviour'].replace(to_replace='!@9#%8', value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replace_payment_behavior.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with either frontfill or backfill\n",
    "\n",
    "df_replace_payment_behavior.ffill(inplace=True)\n",
    "df_replace_payment_behavior.bfill(inplace=True)\n",
    "df_replace_payment_behavior.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move corrected column back into the original dataset\n",
    "\n",
    "df['Payment_Behaviour'] = df_replace_payment_behavior\n",
    "df['Payment_Behaviour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni_eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
